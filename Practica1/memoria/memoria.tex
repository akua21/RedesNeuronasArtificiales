\documentclass{uc3mpracticas}

\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                   Plantilla Prácticas UC3M                               %%%
%%%                Universidad Carlos III de Madrid                          %%%
%%%                   Alejandro Valverde Mahou                               %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Permitir cabeceras y pie de páginas personalizados
\pagestyle{fancy}

%Path por defecto de las imágenes
\graphicspath{ {./images/} }

%Declarar formato de encabezado y pie de página de las páginas del documento
\fancypagestyle{doc}{
  %Cabecera
  \headerpr[1]{Problema de Regresión}{}{Redes de Neuronas Artificiales}
  %Pie de Página
  \footerpr{}{\textbf{UC3M}}{{\thepage} de \pageref{LastPage}}
}

%Declarar formato de encabezado y pie del título e indice
\fancypagestyle{titu}{%
  %Cabecera
  \headerpr{}{}{}
  %Pie de Página
  \footerpr{}{}{}
}


\appto\frontmatter{\pagestyle{titu}}
\appto\mainmatter{\pagestyle{doc}}


\begin{document}
  %Comienzo formato título
  \frontmatter


  %Portada 1 (Centrado todo)
  \centeredtitle{Images/LogoUC3M.png}{Grado en Ingeniería Informática}{Curso 2020/2021}{Redes de Neuronas Artificiales}{Problema de Regresión}{Predicción del precio medio de la vivienda en California}

  \vspace{55mm}

  \authors{Alba Reinders Sánchez}{100383444}{Alejandro Valverde Mahou}{100383383}{}{}{}{}

  \newpage

  %Índice
  \tableofcontents

  \newpage

  %Comienzo formato documento general
  \mainmatter

  \section{Introducción}

  El problema a resolver es la \textbf{predicción del precio medio de la vivenda en California}, usando dos modelos diferentes: \textit{Adaline} y \textit{Perceptron Multicapa}.

  \vspace{3mm}

  El \textit{Adaline} es un modelo \textbf{lineal}, mientras que el \textit{Perceptron Multicapa} es un modelo \textbf{no lineal}. El objetivo de esta práctica es realizar una comparativa entre estos dos modelos mediante la experimentación y análisis de los resultados, para averiguar cuál de los dos es capaz de encontrar la solución más cercana a la solución óptima.

  \section{Preparación de Datos}

  Los datos proporcionados son: \textit{longitude}, \textit{latitude}, \textit{housingMedianAge}, \textit{totalRooms}, \textit{totalBedrooms}, \textit{population}, \textit{households}, \textit{medianIncome}, \textit{\textbf{medianHouseValue}}.

  \vspace{3mm}

  La salida de los modelos deberá ser \textit{\textbf{medianHouseValue}} en función del resto de atributos.

  \vspace{2mm}

  El conjunto de ejemplos proporcionados es de \textbf{17000}.

  \subsection{Normalización}

  El primer paso en el preprocesado de los datos es la \textbf{normalización}. Esta técnica consiste en acotar todos los datos en un rango de 0 a 1. Se ha decidido para este problema, normalizar exclusivamente los atributos de entrada, y no la salida, porque, experimentalmente, resulta en menos error.

  \vspace{3mm}

  La normalización de los datos se realiza cuando los distintos atributos de entrada no están en la misma escala, ya que tener atributos con escalas muy diferentes puede dar lugar al cálculo erróneo de los pesos, lo que deriva en modelos ineficaces.

  \vspace{2mm}

  La transformación lineal que se aplica a cada atributo es:

  \begin{center}
    $$ \mbox{\Large $ atr'_i = \frac{atr_i - \min{(atr)}}{\max{(atr)} - \min{(atr)}} $} $$

  \end{center}



  \subsection{Aleatorización}

  Para evitar un entrenamiento inadecuado, es necesario otorgar a los modelos una lista de datos desordenados, o con orden aleatorio. De esta forma el modelo no se ajusta a un rango concreto de valores, que podrían darse seguidos si no se organizan aleatoriamente.

  \subsection{Separación en conjuntos de datos}

  Dado que este problema tiene una cantidad suficientemente grande de datos, se puede realizar la división del conjunto de datos en 3 subconjuntos:

  \begin{itemize}
    \item \textbf{Conjunto de Entrenamiento}:

    Con él se realiza el aprendizaje (ajuste de pesos) del modelo. Es el conjunto más grande, pues tiene el 60\% de los datos (10200 instancias).

    \item \textbf{Conjunto de Test}:

    Se usa para evaluar la precisión y capacidad de generalización del modelo. Este conjunto tiene el 20\% de los datos (3400 instancias).

    \item \textbf{Conjunto de Validación}:

    Se usa para determinar los mejores hiperparámetros del modelo. Este conjunto tiene el 20\% de los datos (3400 instancias).

  \end{itemize}

  \section{Adaline}

  El lenguaje de programación elegido para el desarrollo del algoritmo \textbf{ADALINE} ha sido \textit{Python}.

    \subsection{Experimentación}

    Se ha decidido realizar distintos experimentos, tanto con salida normalizada como con salida no normalizada, con el objetivo de comprobar cuál ofrece mejores resultados. Además, para cada experimento, se han realizado varias pruebas para encontrar la razón o tasa de aprendizaje más adecuada en cada caso.

    \vspace{3mm}

    En lugar de elegir arbitrariamente un número de ciclos para cada experimento, se ha usado un criterio de parada más específico: el aprendizaje termina cuando el error en el conjunto de validación es mayor o igual que en los 4 ciclos anteriores.

    \vspace{3mm}

    Este criterio de parada es eficaz dado que ayuda a determinar automáticamente el momento en el que el algoritmo converge en un valor concreto, o comienza a tener sobreaprendizaje.

    \vspace{3mm}

    Los experimentos consistirán en ejecutar el algoritmo con una tasa de aprendizaje inicial de \textit{0.5}, que se irá ajustando a lo largo de los experimentos hasta alcanzar la tasa que obtenga los resultados más adecuados.

    \subsection{Resultados Obtenidos}

      \subsubsection*{Salida Normalizada}

      Tabla de resultados obtenidos por experimento:

      \vspace{-4mm}

      \begin{center}
        \begin{tabular}{|l|c|c|c|c|}
          \hline
                                                  & \textbf{Experimento 1} & \textbf{Experimento 2} & \textbf{Experimento 3} & \textbf{Experimento 4}\\ \hline
          \textit{\textbf{Tasa aprend.}}          &  0.5                   &  0.3                   &  0.2                   &  0.1                  \\ \hline
          \textit{\textbf{Ciclos}}                &  5                     &  5                     &  308                   &  566                  \\ \hline
          \textit{\textbf{Err. entren.}}          &  0.1537454242037602    &  0.12999495781099646   &  0.11828832839640416   &  0.10761552626685748  \\ \hline
          \textit{\textbf{Err. valid.}}           &  0.1510858340453369    &  0.1273892127623424    &  0.11546352829888222   &  0.10454524622576246  \\ \hline
          \textit{\textbf{Err. test}}             &  0.1493666202359257    &  0.12539101364386532   &  0.11387419742858149   &  0.10391975176932682  \\ \hline
        \end{tabular}
      \end{center}

      Los experimentos que solo llegan a 5 ciclos es debido a que la tasa de aprendizaje es demasiado grande, y hace que el error crezca en lugar de decrecer.

      \vspace{1mm}

      Experimentalemente, la inicialización aleatoria de los pesos produce que el número de ciclos varíe de enorme manera de una ejecución a otra, usando los mismos hiperparámetros. Los valores que figuran en la tabla son aquellos que se han obtenido con mayor frecuencia a la hora de realizar los experimentos.

      \vspace{1mm}

      Según se ha ido disminuyendo el valor de la tasa de aprendizaje, se han encontrado mejores resultados, hasta llegar a un valor de \textbf{0.1}(Experimento 4). Cualquier valor más pequeño que ese, hace que el algoritmo no acabe en un número de ciclos razonable. La siguiente gráfica muestra la evolución de errores del \textbf{Experimento 4}.


     \imgcenter[112]{Images/evo_err_adaline_norm.png}

      \subsubsection*{Salida No Normalizada}

      Tabla de resultados obtenidos por experimento:

      \vspace{-4mm}

      \begin{center}
        \begin{tabular}{|l|c|c|c|c|}
          \hline
                                                  & \textbf{Experimento 1} & \textbf{Experimento 2} & \textbf{Experimento 3} & \textbf{Experimento 4}\\ \hline
          \textit{\textbf{Tasa aprend.}}          &  0.5                   &  0.22                  &  0.05                  &  0.01                 \\ \hline
          \textit{\textbf{Ciclos}}                &  5                     &  8                     &  30                    &  139                  \\ \hline
          \textit{\textbf{Err. entren.}}          &  69245.64846716617     &  55508.988233795564    &  50017.42808457685     &  49891.46770073132    \\ \hline
          \textit{\textbf{Err. valid.}}           &  69642.07395718427     &  56733.54239803611     &  51961.06532331261     &  52020.971503368535   \\ \hline
          \textit{\textbf{Err. test}}             &  69986.82287304835     &  55858.881817193804    &  50276.791119059315    &  50082.97953387804    \\ \hline
        \end{tabular}
      \end{center}

      Igual que en el caso anterior, se ha ido disminuyendo la tasa de aprendizaje, y en este caso se ha alcanzado el valor de \textbf{0.01}. A partir de ese valor, el algoritmo no converge en un número razonable de ciclos.

     \imgcenter[112]{Images/evo_err_adaline.png}


    \subsection{Análisis}

    \subsubsection*{Salida Normalizada}

      \imgcenter[140]{Images/y_d_adaline_norm.png}

      Como se aprecia en la gráfica anterior, la salida obtenida se acerca a la salida deseada, excepto en los valores más altos(a partir de \$250000), donde se produce una mayor disparidad. Esto puede deberse a que, los valores que van desde los \$0 hasta los \$250000, siguen una distribución relativamente lineal, pero a partir de ese valor parece que aumenta de forma exponencial.

      \vspace{3mm}

      Dado que el algoritmo \textbf{ADALINE} ofrece una salida lineal, es capaz de adecuarse con mayor facilidad que a la segunda parte de los datos.

      \vspace{2mm}

      El valor absoluto medio del error que el modelo produce para el conjunto de test es de \textbf{\$65400.287447627044}.


    \subsubsection*{Salida No Normalizada}

      \imgcenter[140]{Images/y_d_adaline.png}

      Al igual que en el caso del experimento con salida normalizada, se ajusta mejor con los datos de menor valor, pero en este caso sacrifica un poco de precision en los valores de \$0 hasta \$200000 aproximadamente. Sin embargo, hace que el error que produce en los valores altos sea menor.

      \vspace{2mm}

      Gracias a este ajuste, consigue un error medio menor en el conjunto de entrenamiento: \textbf{\$50082.97953387804}.

  \section{Perceptron Multicapa}

    \subsection{Experimentación}

    \subsection{Resultados Obtenidos}

    \subsection{Análisis}

  \section{Comparación de Modelos}

  \section{Conclusiones}



\end{document}
