\documentclass{uc3mpracticas}

\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                   Plantilla Prácticas UC3M                               %%%
%%%                Universidad Carlos III de Madrid                          %%%
%%%                   Alejandro Valverde Mahou                               %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Permitir cabeceras y pie de páginas personalizados
\pagestyle{fancy}

%Path por defecto de las imágenes
\graphicspath{ {./images/} }

%Declarar formato de encabezado y pie de página de las páginas del documento
\fancypagestyle{doc}{
  %Cabecera
  \headerpr[1]{Problema de Regresión}{}{Redes de Neuronas Artificiales}
  %Pie de Página
  \footerpr{}{\textbf{UC3M}}{{\thepage} de \pageref{LastPage}}
}

%Declarar formato de encabezado y pie del título e indice
\fancypagestyle{titu}{%
  %Cabecera
  \headerpr{}{}{}
  %Pie de Página
  \footerpr{}{}{}
}


\appto\frontmatter{\pagestyle{titu}}
\appto\mainmatter{\pagestyle{doc}}


\begin{document}
  %Comienzo formato título
  \frontmatter


  %Portada 1 (Centrado todo)
  \centeredtitle{Images/LogoUC3M.png}{Grado en Ingeniería Informática}{Curso 2020/2021}{Redes de Neuronas Artificiales}{Problema de Regresión}{Predicción del precio medio de la vivienda en California}

  \vspace{55mm}

  \authors{Alba Reinders Sánchez}{100383444}{Alejandro Valverde Mahou}{100383383}{}{}{}{}

  \newpage

  %Índice
  \tableofcontents

  \newpage

  %Comienzo formato documento general
  \mainmatter

  \section{Introducción}

  El problema a resolver es la \textbf{predicción del precio medio de la vivenda en California}, usando dos modelos diferentes: \textit{Adaline} y \textit{Perceptron Multicapa}.

  \vspace{3mm}

  El \textit{Adaline} es un modelo \textbf{lineal}, mientras que el \textit{Perceptron Multicapa} es un modelo \textbf{no lineal}. El objetivo de esta práctica es realizar una comparativa entre estos dos modelos mediante la experimentación y análisis de los resultados, para averiguar cuál de los dos es capaz de encontrar la solución más cercana a la solución óptima.

  \section{Preparación de Datos}

  Los datos proporcionados son: \textit{longitude}, \textit{latitude}, \textit{housingMedianAge}, \textit{totalRooms}, \textit{totalBedrooms}, \textit{population}, \textit{households}, \textit{medianIncome}, \textit{\textbf{medianHouseValue}}.

  \vspace{3mm}

  La salida de los modelos deberá ser \textit{\textbf{medianHouseValue}} en función del resto de atributos.

  \vspace{2mm}

  El conjunto de ejemplos proporcionados es de \textbf{17000}.

  \subsection{Normalización}

  El primer paso en el preprocesado de los datos es la \textbf{normalización}. Esta técnica consiste en acotar todos los datos en un rango de 0 a 1. Se ha decidido para este problema, normalizar exclusivamente los atributos de entrada, y no la salida, porque, experimentalmente, resulta en menos error.

  \vspace{3mm}

  La normalización de los datos se realiza cuando los distintos atributos de entrada no están en la misma escala, ya que tener atributos con escalas muy diferentes puede dar lugar al cálculo erróneo de los pesos, lo que deriva en modelos ineficaces.

  \vspace{2mm}

  La transformación lineal que se aplica a cada atributo es:

  \begin{center}
    $$ \mbox{\Large $ atr'_i = \frac{atr_i - \min{(atr)}}{\max{(atr)} - \min{(atr)}} $} $$

  \end{center}



  \subsection{Aleatorización}

  Para evitar un entrenamiento inadecuado, es necesario otorgar a los modelos una lista de datos desordenados, o con orden aleatorio. De esta forma el modelo no se ajusta a un rango concreto de valores, que podrían darse seguidos si no se organizan aleatoriamente.

  \subsection{Separación en conjuntos de datos}

  Dado que este problema tiene una cantidad suficientemente grande de datos, se puede realizar la división del conjunto de datos en 3 subconjuntos:

  \begin{itemize}
    \item \textbf{Conjunto de Entrenamiento}:

    Con él se realiza el aprendizaje (ajuste de pesos) del modelo. Es el conjunto más grande, pues tiene el 60\% de los datos (10200 instancias).

    \item \textbf{Conjunto de Test}:

    Se usa para evaluar la precisión y capacidad de generalización del modelo. Este conjunto tiene el 20\% de los datos (3400 instancias).

    \item \textbf{Conjunto de Validación}:

    Se usa para determinar los mejores hiperparámetros del modelo. Este conjunto tiene el 20\% de los datos (3400 instancias).

  \end{itemize}

  \section{Adaline}

  El lenguaje de programación elegido para el desarrollo del algoritmo \textbf{ADALINE} ha sido \textit{Python}.

    \subsection{Experimentación}

    Se ha decidido realizar distintos experimentos, tanto con salida normalizada como con salida no normalizada, con el objetivo de comprobar cuál ofrece mejores resultados. Además, para cada experimento, se han realizado varias pruebas para encontrar la razón o tasa de aprendizaje más adecuada en cada caso.

    \vspace{3mm}

    En lugar de elegir arbitrariamente un número de ciclos para cada experimento, se ha usado un criterio de parada más específico: el aprendizaje termina cuando el error en el conjunto de validación es mayor o igual que en los 4 ciclos anteriores.

    \vspace{3mm}

    Este criterio de parada es eficaz dado que ayuda a determinar automáticamente el momento en el que el algoritmo converge en un valor concreto, o comienza a tener sobreaprendizaje.

    \vspace{3mm}

    Los experimentos consistirán en ejecutar el algoritmo con una tasa de aprendizaje inicial de \textit{0.5}, que se irá ajustando a lo largo de los experimentos hasta alcanzar la tasa que obtenga los resultados más adecuados.

    \subsection{Resultados Obtenidos}

      \subsubsection*{Salida Normalizada}

      \textbf{Tabla de resultados obtenidos por experimento:}

      \begin{center}
        \begin{tabular}{|l|c|c|c|c|}
          \hline
                                                  & \textbf{Experimento 1} & \textbf{Experimento 2} & \textbf{Experimento 3} & \textbf{Experimento 4}\\ \hline
          \textit{\textbf{Tasa aprendizaje}}      &  0.5                   &  0.3                   &  0.2                   &  0.23                 \\ \hline
          \textit{\textbf{Ciclos}}                &  5                     &  5                     &  >150                  &  5                    \\ \hline
          \textit{\textbf{Err. entrenamiento}}    &  0.1537454242037602    &  0.12999495781099646   &  ???                   &  0.12146479231784094  \\ \hline
          \textit{\textbf{Err. validación}}       &  0.1510858340453369    &  0.1273892127623424    &  ???                   &  0.11870284063366673  \\ \hline
          \textit{\textbf{Err. test}}             &  0.1493666202359257    &  0.12539101364386532   &  ???                   &  0.1168773340255847   \\ \hline
        \end{tabular}
      \end{center}

      Según se ha ido disminuyendo el valor de la tasa de aprendizaje, se han encontrado mejores resultados, hasta llegar a un valor de \textbf{0.23}(Experimento 4). Cualquier valor más pequeño que ese, hace que el algoritmo no acabe en un número de ciclos razonable.

      \subsubsection*{Salida No Normalizada}

      \textbf{Tabla de resultados obtenidos por experimento:}

      \begin{center}
        \begin{tabular}{|l|c|c|c|c|}
          \hline
                                                  & \textbf{Experimento 1} & \textbf{Experimento 2} & \textbf{Experimento 3} & \textbf{Experimento 4}\\ \hline
          \textit{\textbf{Tasa aprendizaje}}      &  0.5                   &  0.22                  &  0.05                  &  0.01                 \\ \hline
          \textit{\textbf{Ciclos}}                &  5                     &  8                     &  30                    &  139                  \\ \hline
          \textit{\textbf{Err. entrenamiento}}    &  69245.64846716617     &  55508.988233795564    &  50017.42808457685     &  49891.46770073132    \\ \hline
          \textit{\textbf{Err. validación}}       &  69642.07395718427     &  56733.54239803611     &  51961.06532331261     &  52020.971503368535   \\ \hline
          \textit{\textbf{Err. test}}             &  69986.82287304835     &  55858.881817193804    &  50276.791119059315    &  50082.97953387804    \\ \hline
        \end{tabular}
      \end{center}

      Igual que en el caso anterior, se ha ido disminuyendo la tasa de aprendizaje, y en este caso se ha alcanzado el valor de \textbf{0.01}. A partir de ese valor, el algoritmo no converge en un número razonable de ciclos.

    \subsection{Análisis}

  \section{Perceptron Multicapa}

    \subsection{Experimentación}

    \subsection{Resultados Obtenidos}

    \subsection{Análisis}

  \section{Comparación de Modelos}

  \section{Conclusiones}



\end{document}
