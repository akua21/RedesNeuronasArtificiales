\documentclass{uc3mpracticas}

\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                   Plantilla Prácticas UC3M                               %%%
%%%                Universidad Carlos III de Madrid                          %%%
%%%                   Alejandro Valverde Mahou                               %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Permitir cabeceras y pie de páginas personalizados
\pagestyle{fancy}

%Path por defecto de las imágenes
\graphicspath{ {./images/} }

%Declarar formato de encabezado y pie de página de las páginas del documento
\fancypagestyle{doc}{
  %Cabecera
  \headerpr[1]{Problema de Regresión}{}{Redes de Neuronas Artificiales}
  %Pie de Página
  \footerpr{}{\textbf{UC3M}}{{\thepage} de \pageref{LastPage}}
}

%Declarar formato de encabezado y pie del título e indice
\fancypagestyle{titu}{%
  %Cabecera
  \headerpr{}{}{}
  %Pie de Página
  \footerpr{}{}{}
}


\appto\frontmatter{\pagestyle{titu}}
\appto\mainmatter{\pagestyle{doc}}


\begin{document}
  %Comienzo formato título
  \frontmatter


  %Portada 1 (Centrado todo)
  \centeredtitle{Images/LogoUC3M.png}{Grado en Ingeniería Informática}{Curso 2020/2021}{Redes de Neuronas Artificiales}{Problema de Regresión}{Predicción del precio medio de la vivienda en California}

  \vspace{55mm}

  \authors{Alba Reinders Sánchez}{100383444}{Alejandro Valverde Mahou}{100383383}{}{}{}{}

  \newpage

  %Índice
  \tableofcontents

  \newpage

  %Comienzo formato documento general
  \mainmatter

  \section{Introducción}

  El problema a resolver es la \textbf{predicción del precio medio de la vivenda en California}, usando dos modelos diferentes: \textit{ADALINE} y \textit{Perceptrón Multicapa}.

  \vspace{3mm}

  El \textit{ADALINE} es un modelo \textbf{lineal}, mientras que el \textit{Perceptrón Multicapa} es un modelo \textbf{no lineal}. El objetivo de esta práctica es realizar una comparativa entre estos dos modelos mediante la experimentación y análisis de los resultados, para averiguar cuál de los dos es capaz de encontrar la solución más cercana a la solución óptima.

  \section{Preparación de Datos}

  Los datos proporcionados son: \textit{longitude}, \textit{latitude}, \textit{housingMedianAge}, \textit{totalRooms}, \textit{totalBedrooms}, \textit{population}, \textit{households}, \textit{medianIncome}, \textit{\textbf{medianHouseValue}}.

  \vspace{3mm}

  La salida de los modelos deberá ser \textit{\textbf{medianHouseValue}} en función del resto de atributos.

  \vspace{2mm}

  El conjunto de ejemplos proporcionados es de \textbf{17000}.

  \subsection{Normalización}

  El primer paso en el preprocesado de los datos es la \textbf{normalización}. Esta técnica consiste en acotar todos los datos en un rango de 0 a 1. Se ha decidido para este problema, normalizar exclusivamente los atributos de entrada, y no la salida, porque, experimentalmente, resulta en menos error.

  \vspace{3mm}

  La normalización de los datos se realiza cuando los distintos atributos de entrada no están en la misma escala, ya que tener atributos con escalas muy diferentes puede dar lugar al cálculo erróneo de los pesos, lo que deriva en modelos ineficaces.

  \vspace{2mm}

  La transformación lineal que se aplica a cada atributo es:

  \begin{center}
    $$ \mbox{\Large $ atr'_i = \frac{atr_i - \min{(atr)}}{\max{(atr)} - \min{(atr)}} $} $$

  \end{center}



  \subsection{Aleatorización}

  Para evitar un entrenamiento inadecuado, es necesario otorgar a los modelos una lista de datos desordenados, o con orden aleatorio. De esta forma el modelo no se ajusta a un rango concreto de valores, que podrían darse seguidos si no se organizan aleatoriamente.

  \subsection{Separación en conjuntos de datos}

  Dado que este problema tiene una cantidad suficientemente grande de datos, se puede realizar la división del conjunto de datos en 3 subconjuntos:

  \begin{itemize}
    \item \textbf{Conjunto de Entrenamiento}:

    Con él se realiza el aprendizaje (ajuste de pesos) del modelo. Es el conjunto más grande, pues tiene el 60\% de los datos (10200 instancias).

    \item \textbf{Conjunto de Test}:

    Se usa para evaluar la precisión y capacidad de generalización del modelo. Este conjunto tiene el 20\% de los datos (3400 instancias).

    \item \textbf{Conjunto de Validación}:

    Se usa para determinar los mejores hiperparámetros del modelo. Este conjunto tiene el 20\% de los datos (3400 instancias).

  \end{itemize}

  \section{Adaline}

  El lenguaje de programación elegido para el desarrollo del algoritmo \textbf{ADALINE} ha sido \textit{Python}.

    \subsection{Experimentación}

    Se ha decidido realizar distintos experimentos, tanto con salida normalizada como con salida no normalizada, con el objetivo de comprobar cuál ofrece mejores resultados. Además, para cada experimento, se han realizado varias pruebas para encontrar la razón o tasa de aprendizaje más adecuada en cada caso.

    \vspace{3mm}

    En lugar de elegir arbitrariamente un número de ciclos para cada experimento, se ha usado un criterio de parada más específico: el aprendizaje termina cuando el error en el conjunto de validación es mayor o igual que en los 4 ciclos anteriores.

    \vspace{3mm}

    Este criterio de parada es eficaz dado que ayuda a determinar automáticamente el momento en el que el algoritmo converge en un valor concreto, o comienza a tener sobreaprendizaje.

    \vspace{3mm}

    Los experimentos consistirán en ejecutar el algoritmo con una tasa de aprendizaje inicial de \textit{0.5}, que se irá ajustando a lo largo de los experimentos hasta alcanzar la tasa que obtenga los resultados más adecuados.

    \subsection{Resultados Obtenidos}

      \subsubsection*{Salida Normalizada}

      Tabla de resultados obtenidos por experimento:

      \vspace{-4mm}

      \begin{center}
        \begin{tabular}{|l|c|c|c|c|}
          \hline
                                                  & \textbf{Experimento 1} & \textbf{Experimento 2} & \textbf{Experimento 3} & \textbf{Experimento 4}\\ \hline
          \textit{\textbf{Tasa aprend.}}          &  0.5                   &  0.3                   &  0.2                   &  0.1                  \\ \hline
          \textit{\textbf{Ciclos}}                &  5                     &  5                     &  308                   &  566                  \\ \hline
          \textit{\textbf{Err. entren.}}          &  0.1537454242037602    &  0.12999495781099646   &  0.11828832839640416   &  0.10761552626685748  \\ \hline
          \textit{\textbf{Err. valid.}}           &  0.1510858340453369    &  0.1273892127623424    &  0.11546352829888222   &  0.10454524622576246  \\ \hline
          \textit{\textbf{Err. test}}             &  0.1493666202359257    &  0.12539101364386532   &  0.11387419742858149   &  0.10391975176932682  \\ \hline
        \end{tabular}
      \end{center}

      Los experimentos que solo llegan a 5 ciclos es debido a que la tasa de aprendizaje es demasiado grande, y hace que el error crezca en lugar de decrecer.

      \vspace{1mm}

      Experimentalemente, la inicialización aleatoria de los pesos produce que el número de ciclos varíe de enorme manera de una ejecución a otra, usando los mismos hiperparámetros. Los valores que figuran en la tabla son aquellos que se han obtenido con mayor frecuencia a la hora de realizar los experimentos.

      \vspace{1mm}

      Según se ha ido disminuyendo el valor de la tasa de aprendizaje, se han encontrado mejores resultados, hasta llegar a un valor de \textbf{0.1}(Experimento 4). Cualquier valor más pequeño que ese, hace que el algoritmo no acabe en un número de ciclos razonable. La siguiente gráfica muestra la evolución de errores del \textbf{Experimento 4}.


     \imgcenter[112]{Images/evo_err_adaline_norm.png}

      \subsubsection*{Salida No Normalizada}

      Tabla de resultados obtenidos por experimento:

      \vspace{-4mm}

      \begin{center}
        \begin{tabular}{|l|c|c|c|c|}
          \hline
                                                  & \textbf{Experimento 1} & \textbf{Experimento 2} & \textbf{Experimento 3} & \textbf{Experimento 4}\\ \hline
          \textit{\textbf{Tasa aprend.}}          &  0.5                   &  0.22                  &  0.05                  &  0.01                 \\ \hline
          \textit{\textbf{Ciclos}}                &  5                     &  8                     &  30                    &  139                  \\ \hline
          \textit{\textbf{Err. entren.}}          &  69245.64846716617     &  55508.988233795564    &  50017.42808457685     &  49891.46770073132    \\ \hline
          \textit{\textbf{Err. valid.}}           &  69642.07395718427     &  56733.54239803611     &  51961.06532331261     &  52020.971503368535   \\ \hline
          \textit{\textbf{Err. test}}             &  69986.82287304835     &  55858.881817193804    &  50276.791119059315    &  50082.97953387804    \\ \hline
        \end{tabular}
      \end{center}

      Igual que en el caso anterior, se ha ido disminuyendo la tasa de aprendizaje, y en este caso se ha alcanzado el valor de \textbf{0.01}. A partir de ese valor, el algoritmo no converge en un número razonable de ciclos.

     \imgcenter[112]{Images/evo_err_adaline.png}


    \subsection{Análisis}

    \subsubsection*{Salida Normalizada}

      \imgcenter[140]{Images/y_d_adaline_norm.png}

      Como se aprecia en la gráfica anterior, la salida obtenida se acerca a la salida deseada, excepto en los valores más altos(a partir de \$250000), donde se produce una mayor disparidad. Esto puede deberse a que, los valores que van desde los \$0 hasta los \$250000, siguen una distribución relativamente lineal, pero a partir de ese valor parece que aumenta de forma exponencial.

      \vspace{3mm}

      Dado que el algoritmo \textbf{ADALINE} ofrece una salida lineal, es capaz de adecuarse con mayor facilidad que a la segunda parte de los datos.

      \vspace{2mm}

      El valor absoluto medio del error que el modelo produce para el conjunto de test es de \textbf{\$65400.287447627044}.


    \subsubsection*{Salida No Normalizada}

      \imgcenter[140]{Images/y_d_adaline.png}

      Al igual que en el caso del experimento con salida normalizada, se ajusta mejor con los datos de menor valor, pero en este caso sacrifica un poco de precision en los valores de \$0 hasta \$200000 aproximadamente. Sin embargo, hace que el error que produce en los valores altos sea menor.

      \vspace{2mm}

      Gracias a este ajuste, consigue un error medio menor en el conjunto de entrenamiento: \textbf{\$50082.97953387804}.

  \section{Perceptrón Multicapa}

  El \textbf{Perceptrón Multicapa} se ha ejecutado usando el \textit{script} proporcionado, que está en el lenguaje de programación \textit{R}.


    \subsection{Experimentación}

    En este caso, es necesario trabajar con la salida normalizada porque, sino, se produce el efecto de saturación en las neuronas de la red, lo que hace que no sean capaces de aprender.

    \vspace{2mm}

    Por otro lado, la condición de parada en este caso es diferente. Consiste en evaluar el modelo con un número fijo de ciclos y decidir en qué ciclo se ha obtenido mejor resultado, tras ello se vuelve a entrenar a la red usando el número de ciclos óptimo.

    \vspace{2mm}

    Los parámetro configurables de este algoritmo son la \textbf{topología}, la \textbf{razón de aprendizaje} y el número de \textbf{ciclos máximos}. Se ha decidido fijar el número de ciclos máximos para todos los experimentos a \textbf{10000}.

    \vspace{2mm}

    Los experimentos se han llevado a cabo teniendo en cuenta el resultado de experimentos anteriores, para intentar encontrar mejorers resultados con cada uno. A su vez, cada experimento está compuesto de distintos \textit{subexperimentos}, donde se intenta encontar la mejor razón de aprendizaje para cada uno.

    \vspace{2mm}

    Los experimentos que se han llevado a cabo son:

      \begin{itemize}
        \item \textbf{Experimento 1}: la topología de la red consiste en no tener \textbf{ninguna capa oculta}, por lo que se podría considerar que no llega a ser un \textit{Perceptrón Multicapa} al no poseer capas ocultas, pero sirve de caso base para comparar el resto de experimentos.
        \item \textbf{Experimento 2}: tras el experimento anterior se decide configurar un modelo que posee \textbf{una capa oculta} con \textbf{20 neuronas} para buscar la mejora de resultados al añadir una capa oculta.
        \item \textbf{Experimento 3}: como al añadir una capa oculta se comprueba que mejora bastante, se prueba a aumentar el número de neuronas, por lo que este experimento tiene también \textbf{una capa oculta} pero esta vez tiene \textbf{30 neuronas}.
        \item \textbf{Experimento 4}: el último modelo consiste en crear una topología de red con \textbf{dos capas ocultas} cada una con \textbf{30 y 20 neuronas} respectivamente con la que se pretende mejorar aún más la precisión del modelo.
      \end{itemize}



    \subsection{Resultados Obtenidos}

    Tabla de resultados obtenidos por experimento:

    \begin{center}
      \begin{tabular}{|l|c|c|c|c|c|c|}
        \hline
        & \textit{\textbf{Topología}} & \textit{\textbf{Tasa aprend.}} & \textit{\textbf{Ciclos ópt.}} & \textit{\textbf{Err. entren.}} & \textit{\textbf{Err. valid.}} & \textit{\textbf{Err. test}}\\ \hline \hline
        \textbf{Experimento 1-1}&  c( )      &  0.01  &  9998   &  0.09985901  &  0.09648482  &  0.09615899  \\ \hline
        \textbf{Experimento 1-2}&  c( )      &  0.05  &  2835   &  0.09971082  &  0.09638341  &  0.09597574  \\ \hline
        \textbf{Experimento 1-3}&  c( )      &  0.03  &  6553   &  0.09981516  &  0.09646387  &  0.09609764  \\ \hline
        \textbf{Experimento 1-4}&  c( )      &  0.04  &  3368   &  0.09975728  &  0.09641738  &  0.09603159  \\ \hline \hline
        \textbf{Experimento 2-1}&  c(20)     &  0.01  &  10000  &  0.08838755  &  0.08637155  &  0.084649    \\ \hline
        \textbf{Experimento 2-2}&  c(20)     &  0.07  &  10000  &  0.07790314  &  0.07747784  &  0.07685197  \\ \hline
        \textbf{Experimento 2-3}&  c(20)     &  0.15  &  10000  &  0.07818915  &  0.07721448  &  0.07657498  \\ \hline
        \textbf{Experimento 2-4}&  c(20)     &  0.4   &  6096   &  0.076175    &  0.0759147   &  0.07687894  \\ \hline \hline
        \textbf{Experimento 3-1}&  c(30)     &  0.1   &  10000  &  0.07710104  &  0.07670325  &  0.07649249  \\ \hline
        \textbf{Experimento 3-2}&  c(30)     &  0.4   &  10000  &  0.07562609  &  0.07617276  &  0.0765667   \\ \hline
        \textbf{Experimento 3-3}&  c(30)     &  0.7   &  10000  &  0.07562471  &  0.07674079  &  0.07711822  \\ \hline
        \textbf{Experimento 3-4}&  c(30)     &  0.9   &  6828   &  0.07747128  &  0.07813840  &  0.07780503  \\ \hline \hline
        \textbf{Experimento 4-1}&  c(30,20)  &  0.1   &  9880   &  0.06917029  &  0.07142923  &  0.07368347  \\ \hline
        \textbf{Experimento 4-2}&  c(30,20)  &  0.3   &  10000  &  0.0644995   &  0.07030901  &  0.07212733  \\ \hline
        \textbf{Experimento 4-3}&  c(30,20)  &  0.7   &  6687   &  0.06347896  &  0.06924343  &  0.07099247  \\ \hline
        \textbf{Experimento 4-4}&  c(30,20)  &  0.6   &  2525   &  0.06820952  &  0.07108485  &  0.07261085  \\ \hline
      \end{tabular}
    \end{center}


    Los experimentos que tienen un total de 10000 ciclos como número de ciclos óptimos se deben a que la red no consigue converger y al llegar a este número se considera que debe detenerse la ejecución para evitar que cada experimento dure demasiado tiempo.

    \vspace{4mm}

    En el caso de que uno de estos experimetos, que no han tenido tiempo de converger, sea uno de los mejores o el mejor, se volverá a realizar la ejecución pero con un mayor número de ciclos máximos.

    \vspace{5mm}

    Tal y como se puede ver en la tabla anterior, el error de test disminuye según aumenta la complejidad de la topología del modelo. Siendo el \textbf{Experimento 4-3} el que genera menos error con un valor de \textbf{0.07099247}.

    \vspace{4mm}

    La siguiente gráfica muestra la evolución del error de entrenamiento y validación de este experimento, en ella se puede ver como progresan de manera similar, aunque entre la iteración nº 1000 y la nº 2000 se separan y el error de validación aumenta más que el de entrenamiento. Esto puede deberse a un \textit{overfitting}.

    \imgcenter[120]{Images/Exp4_3.png}

    \subsection{Análisis}

    En esta sección se analizan las salidas obtenidas frente a las deseadas del mejor experimento del \textit{Perceptrón Multicapa} (Experimento 4-3):

    \imgcenter[140]{Images/y_d_perceptron.png}

    Se puede observar que tiene un comportamiento muy similar al \textit{ADALINE}, aunque parece tener bastantes más picos. Con este ajuste consigue un error medio en test del: \textbf{\$49430.49}, que sigue siendo un error muy alto.


  \section{Comparación de Modelos}

  Una vez realizados y analizados cada uno de los algoritmos por separado, se procede a su comparación con el objetivo de determinar cuál ofrece una mejor solución al problema planteado. Se van a contrastar los mejores experimetos de cada algoritmo.

  \vspace{4mm}

  Aunque el error del modelo del \textit{Perceptrón Multicapa} sea mejor, no supone una mejora sustancial, e incluso, dado que el tiempo de entrenamiento del perceptrón multicapa es mucho mayor, se podría llegara a considerar que el error del modelo de \textit{ADALINE} es mejor. El modelo de ADALINE usa \textbf{2836} ciclos menos que el del perceptrón multicapa.

  \imgcenter[100]{Images/comparativa.png}

  Tal y como se puede ver en la gráfica anterior, la diferncia entre el error de un algoritmo y otro es ínfima. En concreto, el \textit{ADALINE} se equivoca de media tan solo en \$652.49 más que el \textit{Perceptrón Multicapa}.


  \section{Conclusiones}

  A pesar de que muchas veces se puede considerar que modelos más complejos simpre suponen soluciones más precisas, en aprendizaje automático no siempre es cierto. A veces puede incluso cumplirse lo contrario. En este caso se puede ver algo por el estilo.

  \vspace{3mm}

  Aunque el modelo no lineal tiene mayor complejidad tanto en estructura como en tiempo de entrenamiento, su predicción no está muy lejos de la generada por el modelo lineal \textit{ADALINE}.

  \vspace{4mm}

  Respecto a los conceptos de esta práctica, ha sido especialemnte útil la programación del algoritmo \textit{ADALINE} para ganar confianza y familiarización con la estructura y método de aprendizaje de las redes neuronales, además de ver como influyen los distintos parámetros modificables en ellos.

  \vspace{2mm}

  El \textit{Perceptrón} no aportaba demasiado en tema de conceptos, pero sí ayuda a aprender en qué consiste un proceso de experimentación con una red neuronal, y sirve como toma de contacto con el lenguaje de programación \textit{R}.


\end{document}
