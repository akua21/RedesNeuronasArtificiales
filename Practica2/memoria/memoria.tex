\documentclass{uc3mpracticas}

\usepackage{helvet}
\usepackage{multicol}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{changepage}
\usepackage{geometry}
\usepackage{caption}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                   Plantilla Prácticas UC3M                               %%%
%%%                Universidad Carlos III de Madrid                          %%%
%%%                   Alejandro Valverde Mahou                               %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Permitir cabeceras y pie de páginas personalizados
\pagestyle{fancy}

%Path por defecto de las imágenes
\graphicspath{ {./images/} }

%Declarar formato de encabezado y pie de página de las páginas del documento
\fancypagestyle{doc}{
  %Cabecera
  \headerpr[1]{Problema de Clasificación: Parte I}{}{Redes de Neuronas Artificiales}
  %Pie de Página
  \footerpr{}{\textbf{UC3M}}{{\thepage} de \pageref{LastPage}}
}

%Declarar formato de encabezado y pie del título e indice
\fancypagestyle{titu}{%
  %Cabecera
  \headerpr{}{}{}
  %Pie de Página
  \footerpr{}{}{}
}


\appto\frontmatter{\pagestyle{titu}}
\appto\mainmatter{\pagestyle{doc}}


\begin{document}
  %Comienzo formato título
  \frontmatter


  %Portada 1 (Centrado todo)
  \centeredtitle{Images/LogoUC3M.png}{Grado en Ingeniería Informática}{Curso 2020/2021}{Redes de Neuronas Artificiales}{Problema de Clasificación: Parte I}{Clasificación de imágenes del cielo con el Perceptrón Multicapa}

  \vspace{55mm}

  \authors{Alba Reinders Sánchez}{100383444}{Alejandro Valverde Mahou}{100383383}{}{}{}{}

  \newpage

  %Índice
  \tableofcontents

  \newpage

  %Comienzo formato documento general
  \mainmatter

\section{Introducción}

El problema planteado consiste en clasificar imágenes del cielo con el objetivo de ayudar a la estimación de la radiación solar que incide en un lugar, ya que la cantidad de esta radiación varía si hay nubes o no, y del tipo de las nubes.

\vspace{3mm}

Para ello, se hace una simplificación del problema real reduciendo a tres posibles clases las imágenes:

\begin{itemize}
  \item Cielo Despejado
  \item Nube \textit{(sólo un tipo de nube)}
  \item Multinube \textit{(varios tipos de nube)}
\end{itemize}

Dado que en esta primera parte de la práctica se trabaja con un \textbf{Perceptrón Multicapa}, es necesario transformar la información de la imagen en distintos atributos numéricos.

\vspace{3mm}

Los datos que se usan en esta práctica provienen del \textit{grupo MATRAS de la Universidad de Jaén} y contienen estadísticos y transformaciones de imágenes del cielo completo, que permiten al Perceptrón Multicapa realizar la clasificación.

\vspace{2mm}

El conjunto de datos tiene \textbf{717} instancias con \textbf{12} atributos de entrada y \textbf{1} atributo de salida, la clase.

\begin{enumerate}
  \begin{multicols}{2}
  \item Media del canal azul
  \item Media del canal rojo
  \item Desviación típica del canal azul
  \item Sesgo del canal azul
  \item Diferencia de medias Rojo – Verde
  \item Diferencia de medias Rojo – Azul
  \columnbreak
  \item Diferencia de medias Verde – Azul
  \item Entropía del canal azul
  \item Energía del canal azul
  \item Contraste del canal azul
  \item Homogeneidad del canal azul
  \item Cobertura
  \end{multicols}
\end{enumerate}



\section{Preparación de los datos}

Se debe hacer un preprocesado de los datos para poder realizar de manera más efectiva el entrenamiento de la red. Primero se normaliza el conjunto de datos y después se divide en 4 subconjuntos, ya que se lleva a cabo \textit{validación cruzada estratificada} de 4 hojas.

\subsection{Normalizar}

Es necesario normalizar los datos de entrada, dado que cada atributo suele tener rangos de valores muy diferentes. Normalizarlos en el intervalo [0,1] evita posibles sesgos generados por esta difencia de rangos de los atributos durante el aprendizaje de la red.


\subsection{Preparar los datos para Validación Cruzada Estratificada}

Se realiza esta técnica debido a que las clases están desbalanceadas, por tanto no se puede aplicar la validación cruzada normal y se tiene que llevar a cabo la \textit{estratificada}.

\vspace{2mm}

Para realizar la división de los datos en 4 hojas que mantengan la proporción de instancias de las 3 clases, se crean 4 subconjuntos de las instancias de cada clase y después se junta un subconjunto de cada clase en cada hoja.

\vspace{2mm}

Una vez se tienen las 4 hojas, se crean 4 parejas de ficheros para componer los datos de entrenamiento y test. Combinando las distintas hojas de distinta forma, dejando siempre una para el test. Por último se aleatorizan los datos de entrenamiento para evitar posibles sesgos.



\section{Experimentación y análisis de resultados}

La experimentación con el \textit{Perceptrón Multicapa} se basa en ir haciendo experimentos de manera progresiva intentado conseguir la mejor configuración posible, de forma que tanto el error de entrenamiento como el error de test sea mínimo. Además, dado que las clases no están balanceadas, se tiene que tener en cuenta a su vez el porcentaje de aciertos, siendo esta última medida sobre el conjunto de test la que se va a usar como determinante para decidir qué configuración es mejor que otra.

\vspace{2mm}

 Para ello se van variando los hiperparámetros de la red: la \textbf{topología} de la red, la \textbf{razón de aprendizaje} (\textit{RA}) y el \textbf{número ciclos máximo}. Los distintos experimentos que se crean mantienen la topología pero se va modificando la \textit{RA} que se utiliza.

\vspace{1mm}

Los resultados que se muestran en las distintas tablas son las medias de resultados de las 4 hojas de la \textit{validación cruzada estratificada}. Destacar que el número de ciclos máximos se fija a 10000 en un primer momento, y se probará a modificarlo más adelante.

\subsection{Experimento 1}

Es el caso base desde el que se parte, se tiene \textbf{una única capa oculta con 10 neuronas}. A continuación en la tabla se muestra los resultados obtenidos para las distintas razones de aprendizaje.

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{RA}}  & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        \textit{0,001}        &  \textit{0,3344952944}       &  \textit{0,7629008897}                & \textit{0,4235530262}& \textit{0,6738700565}      \\ \hline
        0,0007                &  0,3549707553                &  0,3823117112                         &  0,4343040342       &  0,3219868173               \\ \hline
        0,01                  &  0,2505371572                &  0,839641527                          &  0,4613691504       &  0,6432438795               \\ \hline
        0,005                 &  0,2792817569                &  0,7991775295                         &  0,4438048242       &  0,6474811676               \\ \hline

  \end{tabular}
\end{center}

Los resultados que se obtienen no son muy prometedores, partiendo del primer subexperimento (se denominará como el original) con \textit{RA} de \textit{0,001}, se intenta ir aumentando o disminuyendo su valor en los siguientes subexperimentos para encontrar la mejor \textit{RA} para esta topología. Después de probar con diferentes valores, se concluye con que la mejor \textit{RA} es la original: \textit{0,001}.

\vspace{2mm}

Se ha podido observar que cuando se disminuye la \textit{RA} los errores son similares pero el porcentaje de aciertos, tanto en entrenamiento como en test disminuye prácticamente a la mitad. Esto puede deberse a que en la mayoría de casos está prediciendo la clase mayoritaria (\textbf{nube}), lo cuál hace que el modelo tenga un error que no es del todo malo, pero el porcentaje de aciertos, como es de esperar, es malo.

\vspace{1mm}

Por otro lado, al aumentar la \textit{RA}, en entrenamiento el error disminuye y el porcentaje de aciertos aumenta, lo que puede ser una buena señal. Pero en test el error aumenta y el porcentaje de aciertos disminuye, lo cuál indica un sobreaprendizaje, haciendo que estos modelos sean peores que el original. Aún así, el modelo original muestra también un claro sobreaprendizaje, lo que se intentará reducir en los siguientes experimentos.


\subsection{Experimento 2}

Al igual que en el experimento anterior, se tiene una única capa oculta pero se aumenta el \textbf{número de neuronas a 100} para comprobar si esto afecta positivamente a los resultados. Los resultados obtenidos para las distintas razones de aprendizaje son:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{RA}}  & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        0,001                 &  0,3410726584                &  0,7643001241                         &  0,4513887673       &  0,6627354049               \\ \hline
        0,005                 &  0,2828611825                &  0,8001163873                         &  0,4455312415       &  0,6613700565               \\ \hline
        \textit{0,0008}       &  \textit{0,3488769075}       &  \textit{0,7582428098}                &  \textit{0,4522441869}&  \textit{0,6669256121}               \\ \hline
        0,0006                &  0,3566408764                &  0,7521984275                         &  0,4524900392       &  0,5525188324               \\ \hline

  \end{tabular}
\end{center}

Tal y como se ve en la tabla, el aumentar el número de neuronas no ha hecho que los resultados mejoren. Primero se aumenta la \textit{RA}, y en este caso, los valores son muy similares al caso original con \textit{0,001} de \textit{RA}.

\vspace{2mm}

Dado que aumentar la \textit{RA} no genera mejores resultados, se prueba a disminuirla. El tercer subexperimento proporciona mejores resultados en el conjunto de test, por lo que se prueba a disminuir todavía más, pero esto empeora los resultados.

\vspace{1mm}

Por tanto, el mejor subexperimento para la topología de este experimento es el que tiene una \textit{RA} de \textit{0,0008}. Sin embargo, no se observa una mejora respecto al mejor del \textbf{Experimento 1}, por lo que se puede concluir que aumentar el número de neuronas con una única capa no genera un cambio significatvo.


\subsection{Experimento 3}

En este caso se aumenta el \textbf{número de capas ocultas a 2, con 10 neuronas cada una}. Se intenta probar si una topología algo más compleja obtiene mejores resultados. Los resultados obtenidos para las distintas razones de aprendizaje son:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{RA}}  & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        0,001                 &  0,3760381966                &  0,3692892613                         &  0,4430659371       &  0,2372175141               \\ \hline
        \textit{0,01}         &  \textit{0,2229600868}       &  \textit{0,851228533}                 &  \textit{0,5159168119}&  \textit{0,6447975518}    \\ \hline
        0,03                  &  0,08668297523               &  0,9432547072                         &  0,662564028        &  0,6235640301               \\ \hline
        0,008                 &  0,2439436857                &  0,8307702255                         &  0,4893574402       &  0,6433145009               \\ \hline

  \end{tabular}
\end{center}

Al principio, los resultados son muy malos, pues tanto el porcentaje de aciertos en entrenamiento como en test es bajísimo para una \textit{RA} de 0,001. Por lo que se intenta probar a aumentarla de forma drástica a 0,01. Esto hace que se obtengan mejores resultados en entrenamiento, pero en test, aunque también mejora, se sigue apreciando bastante sobreaprendizaje.

\vspace{2mm}

Después se intenta ajustar la \textit{RA} un poco más, tanto aumentándola como disminuyéndola, pero no se obtienen mejores resultados, por lo que el mejor subexperimento para la topología de este experimento es el que tiene una \textit{RA} de \textit{0,01}.


\subsection{Experimento 4}

Ya que los resultados que se obtienen con 2 capas ocultas todavía no han conseguido mejorar los valores del caso base, se prueba con una topología ligeramente más compleja: \textbf{3 capas ocultas} con 10 neuronas cada una. Los resultados obtenidos para las distintas razones de aprendizaje son:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{RA}}  & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        0,001                 &  0,4362842418                &  0,06694599628                        &  0,4363116735       &  0,06694915254              \\ \hline
        \textit{0,01}         &  \textit{0,2587682627}       &  \textit{0,8191754604}                &  \textit{0,4534598606}&  \textit{0,6962806026}    \\ \hline
        0,008                 &  0,2977744114                &  0,6734171322                         &  0,4198154056       &  0,5252118644               \\ \hline

  \end{tabular}
\end{center}

El primer subexperimento no era muy prometedor. Sin embargo, al aumentar la \textit{RA} a \textit{0,01} se consiguen los mejores resultados hasta el momento, mejorando incluso los valores del \textbf{Experimento 1}.

\vspace{2mm}

Dado que aumentar la \textit{RA} parece positivo para esta topología, se prueba a aumentar más su valor. Pero al hacer esto se observa que la evolución del error oscila mucho demostrando así que la \textit{RA} es demasiado alta y por ello no se puede aumentar más allá de 0,01.

\vspace{2mm}

Se intenta probar a disminuirla con el objetivo de encontrar la \textit{RA} óptima, pero los mejores resultados siguen siendo los obtenidos con el experimento que tiene una \textit{RA} de \textit{0,01}. Ya que es con el que mayor porcentaje de aciertos en test genera.


\subsection{Experimento 5}

Como con una topología más compleja se consiguen mejores resultados, se decide seguir aumentando esta complejidad con: \textbf{4 capas ocultas} con 10 neuronas cada una. Los resultados obtenidos para las distintas razones de aprendizaje son:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{RA}}  & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        0,001                 &  0,4363243875                &  0,06694599628                        &  0,4362894737       &  0,06694915254              \\ \hline
        0,01                  &  0,436545285                 &  0,06694599628                        &  0,4363050425       &  0,06694915254              \\ \hline
        \textit{0,02}         &  \textit{0,365291525}        &  \textit{0,1727989861}                &  \textit{0,4416298473}&  \textit{0,1692561205}    \\ \hline

  \end{tabular}
\end{center}

Los resultados de los distintos subexperimentos no son buenos en ningún caso. Si se intenta introducir una \textit{RA} mayor a \textit{0,02}, los valores de error varían demasiado, indicando que es demasiado alta. Por debajo de \textit{0,01} se estancan en valores muy similares a los obtenidos con \textit{0,01} y \textit{0,001}, por tanto, se puede decir que esta topología no es buena para resolver el problema planteado.

\vspace{1mm}

A pesar de que su valor es muy inferior al de resto de experimentos, el mejor resultado es el que se obtiene con una \textit{RA} de \textit{0,02}.



\subsection{Experimento para intentar reducir el sobreaprendizaje}

Como que se aprecia que todos los experimentos sufren de bastante sobreaprendizaje, se intenta reducirlo \textit{limitando el número de ciclos en el entrenamiento}. Se limita al número de ciclos en el que obtienen su error más bajo en el conjunto de test. Esto se va a realizar sobre los mejores subexperimentos de cada experimento, listados en la siguiente tabla resumen:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{Nombre Exp.}}     & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        Exp. 1-1         &  0,3344952944       &  0,7629008897                &  0,4235530262   &  0,6738700565     \\ \hline
        Exp. 2-3         &  0,2229600868       &  0,851228533                 &  0,5159168119   &  0,6447975518     \\ \hline
        Exp. 3-2         &  0,2229600868       &  0,851228533                 &  0,5159168119   &  0,6447975518     \\ \hline
        Exp. 4-2         &  0,2587682627       &  0,8191754604                &  0,4534598606   &  0,6962806026     \\ \hline
        Exp. 5-3         &  0,365291525        &  0,1727989861                &  0,4416298473   &  0,1692561205     \\ \hline
  \end{tabular}
\end{center}


Para llevar a cabo esta tarea se realiza el mismo acercamiento que se hizo en la primera práctica para poder quedarnos con el número de ciclos óptimo que minimiza el error. Se repiten los subexperimentos de la anterior tabla pero esta vez aplicando esta técnica.


\begin{center}
  \begin{adjustwidth}{-1.4cm}{}
    \begin{tabular}{|c|c|c|c|c|c|}
      \hline
          \textit{\textbf{Nombre Exp.}}     & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test} & \textbf{Núm. ciclos} \\ \hline
          Exp. 1-1         &  0,3658924266       &  0,4649493068                &  0,4014796408   &  0,5585922787   &  7180,25  \\ \hline
          Exp. 2-3         &  0,3983796585       &  0,2805891786                &  0,4175185209   &  0,2322033898   &  3754     \\ \hline
          Exp. 3-2         &  0,3545379908       &  0,3487766398                &  0,3796682922   &  0,33173258     &  2142,75  \\ \hline
          Exp. 4-2         &  0,3486060242       &  0,3504034761                &  0,3776217959   &  0,3294020716   &  4918,75  \\ \hline
          Exp. 5-3         &  0,3860130839       &  0,1727989861                &  0,4110949435   &  0,1692561205   &  8145     \\ \hline
    \end{tabular}
  \end{adjustwidth}
\end{center}

Se puede apreciar en la tabla anterior que hacer esto no genera mejores resultados. De hecho, genera peores. Esto se debe a que minimizar el error que comete la red no es lo mismo que aumentar el porcentaje de aciertos, dado que lo que se busca es maximizar este porcentaje de aciertos, usar esta técnica no resulta apropiada en este caso.



\subsection{Análisis del mejor experimeto}

El experimento que genera mejores resultados es el \textbf{Experimento 4-2}, con un porcentaje de aciertos sobre el conjunto de test de \textbf{0,6962806026}, una topología de 3 capas ocultas con 10 neuronas cada una, una \textit{RA} de 0,01 y 10000 ciclos.

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textit{\textbf{Nombre Exp.}}     & \textbf{Error entrenamiento} & \textbf{\% de aciertos entrenamiento} & \textbf{Error test} & \textbf{\% de aciertos test}\\ \hline
        Exp. 4-2         &  0,2587682627       &  0,8191754604                &  0,4534598606   &  0,6962806026     \\ \hline
  \end{tabular}
\end{center}

La evolución del error sobre el conjunto de test y el conjunto de entrenamiento a lo largo del aprendizaje se puede ver en las siguientes gráficas para cada una de las hojas:

\begin{figure}[!h]
\centering
\begin{minipage}{.52\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{Images/best_fold1.png}
  \caption*{Hoja 1}
\end{minipage}%
\begin{minipage}{.52\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{Images/best_fold2.png}
  \caption*{Hoja 2}
\end{minipage}
\end{figure}


\begin{figure}[!h]
\centering
\begin{minipage}{.52\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{Images/best_fold3.png}
  \caption*{Hoja 3}
\end{minipage}%
\begin{minipage}{.52\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{Images/best_fold4.png}
  \caption*{Hoja 4}
\end{minipage}
\end{figure}


Se observa claramente que, a pesar de que este sea el mejor experimento conseguido, sigue produciendo mucho sobreaprendizaje en el error. En algunos casos más grande que en otros.

\vspace{2mm}

Por ejemplo, la hoja 1 y la hoja 4 son las que sufren menor sobreaprendizaje. Mientras que la hoja 2 y la hoja 3 sufren más sobreaprendizaje, especialmente la 2.

\vspace{2mm}

Se cree que en los primeros ciclos, cuando el error se mantiene estable, quiere decir que la red ha aprendido a determinar que todos, o casi todos, los ejemplos pertenecen a la clase mayoritaria. Es fundamental que un buen modelo sea capaz de superar ese umbral porque si no es capaz de hacerlo, su porcentaje de aciertos en test no podrá superar el valor de 0,07, el cual es muy bajo. Esto ocurre, por ejemplo, en el experimento 4-1, 5-1 y 5-2.

\vspace{1mm}

La evolución del error de todos estos experimentos 'malos' tienen una forma muy parecida, que es la siguiente:



\section{Conclusión}


\end{document}
