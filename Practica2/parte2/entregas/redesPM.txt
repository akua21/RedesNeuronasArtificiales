Experimento 1 PM

def create_simple_pm():
  #modelo simple de pm
  #se usa la sigmoide pero puede utilizarse la función de activación relu
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.BatchNormalization(input_shape=(32, 32, 3)))
  model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3), name="Input_layer"))
  model.add(tf.keras.layers.Dense(50, activation='sigmoid', name="Hidden_layer"))
  model.add(tf.keras.layers.Dense(10, activation='softmax', name="Output_layer"))
  return model

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),
            loss='sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy'])

epochs = 25

historico = model.fit(train_images, train_labels, epochs=epochs, validation_freq=1,
                      validation_data=(test_images, test_labels))

--------------------------------------------------------------------------------
Experimento 2 PM

def create_simple_pm():
  #modelo simple de pm
  #se usa la sigmoide pero puede utilizarse la función de activación relu
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.BatchNormalization(input_shape=(32, 32, 3)))
  model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3), name="Input_layer"))
  model.add(tf.keras.layers.Dense(25, activation='sigmoid', name="Hidden_layer"))
  model.add(tf.keras.layers.Dense(10, activation='softmax', name="Output_layer"))
  return model

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),
            loss='sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy'])

epochs = 21

historico = model.fit(train_images, train_labels, epochs=epochs, validation_freq=1,
                      validation_data=(test_images, test_labels))

--------------------------------------------------------------------------------
Experimento 3 PM

def create_simple_pm():
  #modelo simple de pm
  #se usa la sigmoide pero puede utilizarse la función de activación relu
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.BatchNormalization(input_shape=(32, 32, 3)))
  model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3), name="Input_layer"))
  model.add(tf.keras.layers.Dense(100, activation='sigmoid', name="Hidden_layer"))
  model.add(tf.keras.layers.Dense(10, activation='softmax', name="Output_layer"))
  return model

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),
            loss='sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy'])

epochs = 16

historico = model.fit(train_images, train_labels, epochs=epochs, validation_freq=1,
                      validation_data=(test_images, test_labels))

--------------------------------------------------------------------------------
Experimento 4 PM

def create_simple_pm():
  #modelo simple de pm
  #se usa la sigmoide pero puede utilizarse la función de activación relu
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.BatchNormalization(input_shape=(32, 32, 3)))
  model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3), name="Input_layer"))
  model.add(tf.keras.layers.Dense(100, activation='sigmoid', name="Hidden_layer"))
  model.add(tf.keras.layers.Dense(100, activation='sigmoid', name="Hidden_layer_2"))
  model.add(tf.keras.layers.Dense(10, activation='softmax', name="Output_layer"))
  return model

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),
            loss='sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy'])

epochs = 30

historico = model.fit(train_images, train_labels, epochs=epochs, validation_freq=1,
                      validation_data=(test_images, test_labels))

--------------------------------------------------------------------------------
Experimento 5 PM

def create_simple_pm():
  #modelo simple de pm
  #se usa la sigmoide pero puede utilizarse la función de activación relu
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.BatchNormalization(input_shape=(32, 32, 3)))
  model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3), name="Input_layer"))
  model.add(tf.keras.layers.Dense(100, activation='sigmoid', name="Hidden_layer"))
  model.add(tf.keras.layers.Dense(100, activation='sigmoid', name="Hidden_layer_2"))
  model.add(tf.keras.layers.Dense(100, activation='sigmoid', name="Hidden_layer_3"))
  model.add(tf.keras.layers.Dense(10, activation='softmax', name="Output_layer"))
  return model

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),
            loss='sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy'])

epochs = 23

historico = model.fit(train_images, train_labels, epochs=epochs, validation_freq=1,
                      validation_data=(test_images, test_labels))

--------------------------------------------------------------------------------
